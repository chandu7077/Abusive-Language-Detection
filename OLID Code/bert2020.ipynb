{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert2020",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import datetime\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY6ocyijAKdX",
        "colab_type": "code",
        "outputId": "2e556bf1-d229-47d7-e34d-d7ae8d7a2d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "#TPU SET UP\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'NO TPU IS CONNECTED'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  #print('TPU devices:')\n",
        "  #pprint.pprint(session.list_devices())\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4a0ecd925093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TPU SET UP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NO TPU IS CONNECTED'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mTPU_ADDRESS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'grpc://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TPU address is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTPU_ADDRESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: NO TPU IS CONNECTED"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nDlhPR65kpg",
        "colab_type": "code",
        "outputId": "878500b0-ead5-414a-9239-095b0368251c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session() as session:\n",
        "  #print('TPU devices:')\n",
        "  #pprint.pprint(session.list_devices())\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab_type": "code",
        "outputId": "ce4103a0-fb04-4bbf-d976-d20ac4c485ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "#IMPORTING BERT PYTHON MODULES\n",
        "import sys\n",
        "!test -d bert_repo || git clone https://github.com/chandu7077/mybert.git bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 36 (delta 12), reused 30 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w09zVYygSXJ",
        "colab_type": "code",
        "outputId": "4f6e2cfb-9ee1-420d-d6a5-5348dd314f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# import python modules defined by BERT\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import run_classifier_with_tfhub\n",
        "import tokenization\n",
        "# import tfhub for loading the model\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab_type": "code",
        "outputId": "ed0c5bdc-168d-4644-b6d3-db2233e33607",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#SETTING OUTPUT DIRECTORY AND TFHUB FOR LOADING PRETRAINED MODEL\n",
        "BUCKET = 'bertbase_final'\n",
        "OUTPUT_DIR = 'gs://{}/{}'.format(\"olidtaskb\",BUCKET)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('MODEL OUTPUT DIRECTORY : {0}'.format(OUTPUT_DIR))\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'cased_L-12_H-768_A-12' \n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL OUTPUT DIRECTORY : gs://olidtaskb/bertbase_final\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TylDOYd-6AH-",
        "colab_type": "code",
        "outputId": "6cc6d7bd-ce63-4f27-d4d6-895de302b488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "#bert tokenizer\n",
        "tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJp70mvBIUYR",
        "colab_type": "code",
        "outputId": "4ec98c48-f58d-45e0-d4be-fa8ffb7f97ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "!gsutil cp gs://olidtaska/task_a_distant.tsv train.tsv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://olidtaska/task_a_distant.tsv...\n",
            "- [1 files][  1.2 GiB/  1.2 GiB]   84.2 MiB/s                                   \n",
            "Operation completed over 1 objects/1.2 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb1CsshgIsw3",
        "colab_type": "code",
        "outputId": "5dfff30f-bac2-4a25-bc8b-b2c38bd2167a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "import pandas as pd\n",
        "traint=pd.read_csv(\"train.tsv\",sep=\"\\t\")\n",
        "offdf=traint[traint.average>0.51]\n",
        "offdf[\"label\"]=0\n",
        "notdf=traint[traint.average<0.5]\n",
        "notdf[\"label\"]=1\n",
        "notdf=notdf.sample(len(offdf))\n",
        "fulltrain=pd.concat([offdf,notdf])\n",
        "fulltrain=fulltrain.sample(700000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1789e9d3c86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moffdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.51\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moffdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnotdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File train.tsv does not exist: 'train.tsv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_iAfyj2Jb-1",
        "colab_type": "code",
        "outputId": "2c72eb21-32e1-43c5-8fa8-3f6582c567bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(fulltrain, train_size = 0.5)\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((350000, 5), (350000, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJsd4KJfviyn",
        "colab_type": "code",
        "outputId": "eb2dddc0-3f0b-4e6d-d9e3-4b5a974d2fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train[train.label==1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>average</th>\n",
              "      <th>std</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4632479</th>\n",
              "      <td>1156316762285080576</td>\n",
              "      <td>@USER Hawkeye had a bow</td>\n",
              "      <td>0.165136</td>\n",
              "      <td>0.189946</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407985</th>\n",
              "      <td>1160606782693101569</td>\n",
              "      <td>And what is wrong with referring to GCF in Tok...</td>\n",
              "      <td>0.298868</td>\n",
              "      <td>0.222644</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4851889</th>\n",
              "      <td>1158592628809707525</td>\n",
              "      <td>@USER Was literally about to send this to you 😂</td>\n",
              "      <td>0.307679</td>\n",
              "      <td>0.246101</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2820208</th>\n",
              "      <td>1161596856578826240</td>\n",
              "      <td>Lettuce and cucumbers ruin the Kota. Please do...</td>\n",
              "      <td>0.380284</td>\n",
              "      <td>0.094279</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7885122</th>\n",
              "      <td>1186389186120687616</td>\n",
              "      <td>@USER @USER I don't disagree, I'm just saying ...</td>\n",
              "      <td>0.234198</td>\n",
              "      <td>0.185946</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4590444</th>\n",
              "      <td>1158325291095384066</td>\n",
              "      <td>@USER @USER Man, I haven't seen you in awhile.</td>\n",
              "      <td>0.316796</td>\n",
              "      <td>0.300240</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3564794</th>\n",
              "      <td>1162304750257229826</td>\n",
              "      <td>@USER We had so much fun running in circle tog...</td>\n",
              "      <td>0.238397</td>\n",
              "      <td>0.171877</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499809</th>\n",
              "      <td>1161442304810475524</td>\n",
              "      <td>@USER @USER @USER @USER Ah, I fell for the bai...</td>\n",
              "      <td>0.224512</td>\n",
              "      <td>0.131600</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139200</th>\n",
              "      <td>1160789876595396608</td>\n",
              "      <td>@USER @USER @USER Ps, the club didn’t act on i...</td>\n",
              "      <td>0.218473</td>\n",
              "      <td>0.182455</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611501</th>\n",
              "      <td>1158368324318900224</td>\n",
              "      <td>@USER this seems a little angry?  did you appl...</td>\n",
              "      <td>0.357814</td>\n",
              "      <td>0.177934</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175381 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          id  ... label\n",
              "4632479  1156316762285080576  ...     1\n",
              "407985   1160606782693101569  ...     1\n",
              "4851889  1158592628809707525  ...     1\n",
              "2820208  1161596856578826240  ...     1\n",
              "7885122  1186389186120687616  ...     1\n",
              "...                      ...  ...   ...\n",
              "4590444  1158325291095384066  ...     1\n",
              "3564794  1162304750257229826  ...     1\n",
              "499809   1161442304810475524  ...     1\n",
              "139200   1160789876595396608  ...     1\n",
              "4611501  1158368324318900224  ...     1\n",
              "\n",
              "[175381 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aHo3C4TNGbm",
        "colab_type": "code",
        "outputId": "0f3c3ba0-874e-406d-e39d-ea1d9b943e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7TvaXN8Drn7",
        "colab_type": "code",
        "outputId": "89e84adb-aca5-41c1-ec98-5fe356728fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def remove_noise(tweet):\n",
        "    noises = ['URL', '@USER', '\\'ve', 'n\\'t', '\\'s', '\\'m']\n",
        "    for noise in noises:\n",
        "      tweet=str(tweet)\n",
        "      tweet = tweet.replace(noise, '')\n",
        "    return tweet\n",
        "\n",
        "train.sentence=train.sentence.apply(lambda x:remove_noise(x))\n",
        "test.sentence=test.sentence.apply(lambda x:remove_noise(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e72ee6b1da72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremove_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mremove_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sentence'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqLScO8VvzYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample from bert run_classifier\n",
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'label'\n",
        "label_list = [0,1]\n",
        "train_examples = train.apply(lambda x: run_classifier.InputExample(guid=None, #unique ID for each text (optional)\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_examples = test.apply(lambda x: run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                  label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UhCVhsyTRM-",
        "colab_type": "code",
        "outputId": "d42d356f-ea32-4048-b3b8-0c14032f615c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "train_examples[1011739].text_a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-78a8b202cc3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_examples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1011739\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4402\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4404\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1011739"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUbkH_KpL4vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.mean(train.text,appl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4GQEzy4g0pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state=[]\n",
        "def create_model(is_training, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels, bert_hub_module_handle):\n",
        "  global state\n",
        "  batch_size=8\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  tags = set()\n",
        "  if is_training:\n",
        "    tags.add(\"train\")\n",
        "  bert_module = hub.Module(bert_hub_module_handle, tags=tags, trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  output_layer=bert_outputs[\"sequence_output\"]\n",
        "  \n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels,768 ],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    t1=output_layer[:,1:21]\n",
        "    t2=output_layer[:,0]\n",
        "    lstmcell =  tf.nn.rnn_cell.LSTMCell(768, state_is_tuple=True)\n",
        "    outputs, states = tf.nn.dynamic_rnn(lstmcell,\n",
        "                                  t1,\n",
        "                                  sequence_length=[20]*t1.shape[0].value,\n",
        "                                  dtype=tf.float32)\n",
        "    \n",
        "    output_layer=tf.reduce_mean([t2,states.h],0)\n",
        "    state.append(states.h)\n",
        "    if is_training:\n",
        "      # I.e., 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.sigmoid(logits)\n",
        "    #log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "    per_example_loss=tf.nn.weighted_cross_entropy_with_logits(\n",
        "    labels=one_hot_labels,\n",
        "    logits=logits,\n",
        "    pos_weight=1,\n",
        "    name=None,\n",
        "    targets=None)\n",
        "    #per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, per_example_loss, logits, probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzLKRCzWOImU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL FUNCTION BUILDER\n",
        "train_hook_list= []\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps, use_tpu, bert_hub_module_handle):\n",
        "  def model_fn(features, labels, mode, params):\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "    # input ids which are obtained from bert tokenizer\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    # input masks to represent the actual sentence and padding sequence\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    # segment ids to distinguish in case of two sentence tasks (not needed for this task)\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    # label for sentence \n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "        is_training, input_ids, input_mask, segment_ids, label_ids, num_labels,\n",
        "        bert_hub_module_handle)\n",
        "\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "      \n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(per_example_loss, label_ids, logits):\n",
        "        predicted_labels = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        loss = tf.metrics.mean(per_example_loss)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        out={\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "        train_hook_list.append(tf.train.LoggingTensorHook(\n",
        "                      tensors=out, every_n_iter=100))\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "    \n",
        "      eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metrics=eval_metrics)\n",
        "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      if use_tpu:\n",
        "        output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode, predictions={\"probabilities\": probabilities})\n",
        "      else:\n",
        "        output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                predictions={\"probabilities\": probabilities},\n",
        "                scaffold=None)\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          \"Only TRAIN, EVAL and PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYVYULZiKvUi",
        "colab_type": "code",
        "outputId": "1c648f34-9b40-485c-cd85-5e4687dd3a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "TRAIN_BATCH_SIZE = 64\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1.0\n",
        "MAX_SEQ_LENGTH = 128\n",
        "WARMUP_PROPORTION = 0.1\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "SAVE_SUMMARY_STEPS = 500\n",
        "num_train_steps = int(100000 / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "TPU_ADDRESS=None\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "\n",
        "def get_run_config(output_dir):\n",
        "  return tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=output_dir,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "print(\"no of train steps:\",num_train_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1c3328af50ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_steps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mWARMUP_PROPORTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mTPU_ADDRESS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtpu_cluster_resolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTPU_ADDRESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mNUM_TPU_CORES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mITERATIONS_PER_LOOP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/distribute/cluster_resolver/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tpu, zone, project, job_name, coordinator_name, coordinator_address, credentials, service, discovery_url)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please provide a TPU Name to connect to.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# self._tpu is always bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please provide a TPU Name to connect to."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUXX1wTd7SzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOtKzoT8uLHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR=\"gs://olid2020/basea2\"\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=500,\n",
        "    keep_checkpoint_max=1,\n",
        "    save_checkpoints_steps=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwcsdbLuIX2I",
        "colab_type": "code",
        "outputId": "6b342b1e-7779-457c-aca5-5ce158edea1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Force TF Hub writes to the GS bucket we provide.\n",
        "import os\n",
        "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
        "\n",
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "DATA_COLUMN = 'text'\n",
        "\n",
        "LABEL_COLUMN = 'label'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [0,1]\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=False,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB\n",
        ")\n",
        "\"\"\"\n",
        "estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=False,\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  #config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": 1})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://olid2020/basea2', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd62fbdeb00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://olid2020/basea2', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd62fbdeb00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_c8s2AvhgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "history=None\n",
        "#tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n",
        "def model_train(estimator):\n",
        "  train_features = run_classifier.convert_examples_to_features(\n",
        "      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('Started training at {}'.format(datetime.datetime.now()))\n",
        "  train_input_fn = run_classifier.input_fn_builder(\n",
        "      features=train_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  history=estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print('Finished training at {}'.format(datetime.datetime.now()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRhzyk4_WD2n",
        "colab_type": "code",
        "outputId": "2dce55ec-c666-42e9-99cf-166f274dc5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7935
        }
      },
      "source": [
        "model_train(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/run_classifier.py:767: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/run_classifier.py:767: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 50000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 50000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 60000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 60000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 70000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 70000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 80000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 80000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 90000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 90000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 100000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 100000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 110000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 110000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 120000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 120000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 130000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 130000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 140000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 140000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 150000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 150000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 160000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 160000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 170000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 170000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 180000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 180000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 190000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 190000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 200000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 200000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 210000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 210000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 220000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 220000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 230000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 230000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 240000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 240000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 250000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 250000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 260000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 260000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 270000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 270000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 280000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 280000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 290000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 290000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 300000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 300000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 310000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 310000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 320000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 320000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 330000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 330000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 340000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 340000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Started training at 2020-05-22 03:58:16.491768\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.121.53.34:8470) for TPU system metadata.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.121.53.34:8470) for TPU system metadata.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2515633531048112650)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2515633531048112650)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3900855967440974192)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3900855967440974192)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2611862256532515247)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2611862256532515247)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2850615604283964336)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2850615604283964336)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15822331449183245536)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15822331449183245536)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13203656899024254807)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13203656899024254807)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 740907540828183046)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 740907540828183046)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14879393891027502304)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14879393891027502304)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15476730980657790074)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15476730980657790074)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 44740701558788593)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 44740701558788593)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16151803562553540026)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16151803562553540026)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Features ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Features ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_ids, shape = (8, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_ids, shape = (8, 128)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_mask, shape = (8, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_mask, shape = (8, 128)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = label_ids, shape = (8,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = label_ids, shape = (8,)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = segment_ids, shape = (8, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = segment_ids, shape = (8, 128)\n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ebf3b9a3eeb5>:33: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ebf3b9a3eeb5>:33: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ebf3b9a3eeb5>:37: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ebf3b9a3eeb5>:37: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ebf3b9a3eeb5>:43: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ebf3b9a3eeb5>:43: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ebf3b9a3eeb5>:55: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "targets is deprecated, use labels instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ebf3b9a3eeb5>:55: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "targets is deprecated, use labels instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert_repo/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TPU job name worker\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TPU job name worker\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into gs://olid2020/basea2/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into gs://olid2020/basea2/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized dataset iterators in 21 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized dataset iterators in 21 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Installing graceful shutdown hook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Installing graceful shutdown hook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Init TPU system\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Init TPU system\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized TPU in 0 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized TPU in 0 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting infeed thread controller.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting infeed thread controller.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting outfeed thread controller.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting outfeed thread controller.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 949)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 949)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1000 into gs://olid2020/basea2/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1000 into gs://olid2020/basea2/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.003504474, step = 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.003504474, step = 1000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (562) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (562) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (562) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (562) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (1, 187)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (1, 187)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.596612, step = 1562 (41.238 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.596612, step = 1562 (41.238 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 13.6283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 13.6283\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:examples/sec: 872.209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:examples/sec: 872.209\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1562 into gs://olid2020/basea2/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1562 into gs://olid2020/basea2/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Stop infeed thread controller\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Stop infeed thread controller\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutting down InfeedController thread.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutting down InfeedController thread.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Infeed thread finished, shutting down.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Infeed thread finished, shutting down.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:infeed marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:infeed marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Stop output thread controller\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Stop output thread controller\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutting down OutfeedController thread.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutting down OutfeedController thread.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:outfeed marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:outfeed marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutdown TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutdown TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.596612.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.596612.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:training_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:training_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished training at 2020-05-22 04:07:48.084730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXRtSPZvdiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_eval(estimator,test_examples):\n",
        "  # Eval the model.\n",
        "  eval_examples = test_examples\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
        "  # the last batch.\n",
        "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bc56tAlHtLm",
        "colab_type": "code",
        "outputId": "6233ff85-5de5-426c-80e2-e12ba9c3ecf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6147
        }
      },
      "source": [
        "model_eval(estimator_from_tfhub,test_examples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 50000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 50000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 60000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 60000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 70000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 70000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 80000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 80000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 90000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 90000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 100000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 100000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 110000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 110000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 120000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 120000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 130000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 130000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 140000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 140000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 150000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 150000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 160000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 160000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 170000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 170000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 180000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 180000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 190000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 190000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 200000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 200000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 210000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 210000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 220000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 220000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 230000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 230000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 240000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 240000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 250000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 250000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 260000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 260000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 270000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 270000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 280000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 280000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 290000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 290000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 300000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 300000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 310000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 310000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 320000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 320000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 330000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 330000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 340000 of 350000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 340000 of 350000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Started evaluation at 2020-05-22 04:09:28.889616 *****\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Features ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Features ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_ids, shape = (1, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_ids, shape = (1, 128)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_mask, shape = (1, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = input_mask, shape = (1, 128)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = label_ids, shape = (1,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = label_ids, shape = (1,)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = segment_ids, shape = (1, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  name = segment_ids, shape = (1, 128)\n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
            "ERROR:absl:Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3322: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3322: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-05-22T04:11:23Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-05-22T04:11:23Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TPU job name worker\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TPU job name worker\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://olid2020/basea2/model.ckpt-1562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://olid2020/basea2/model.ckpt-1562\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Init TPU system\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Init TPU system\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized TPU in 0 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized TPU in 0 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized dataset iterators in 21 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initialized dataset iterators in 21 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (43750) batch(es) of data to infeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enqueue next (43750) batch(es) of data to infeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (43750) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Dequeue next (43750) batch(es) of data from outfeed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 16823)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 16823)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 35890)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed finished for iteration (0, 35890)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [43750/43750]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [43750/43750]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Stop infeed thread controller\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Stop infeed thread controller\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutting down InfeedController thread.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutting down InfeedController thread.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Infeed thread finished, shutting down.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Infeed thread finished, shutting down.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:infeed marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:infeed marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Stop output thread controller\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Stop output thread controller\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutting down OutfeedController thread.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutting down OutfeedController thread.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:outfeed marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:outfeed marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutdown TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Shutdown TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-05-22-04:14:53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-05-22-04:14:53\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1562: eval_accuracy = 0.9591171, false_negatives = 9908.0, false_positives = 4401.0, global_step = 1562, loss = 0.15441038, precision = 0.9740276, recall = 0.9433686, true_negatives = 170643.0, true_positives = 165048.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1562: eval_accuracy = 0.9591171, false_negatives = 9908.0, false_positives = 4401.0, global_step = 1562, loss = 0.15441038, precision = 0.9740276, recall = 0.9433686, true_negatives = 170643.0, true_positives = 165048.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1562: gs://olid2020/basea2/model.ckpt-1562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1562: gs://olid2020/basea2/model.ckpt-1562\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:evaluation_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:evaluation_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Finished evaluation at 2020-05-22 04:15:23.011051 *****\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.9591171\n",
            "  false_negatives = 9908.0\n",
            "  false_positives = 4401.0\n",
            "  global_step = 1562\n",
            "  loss = 0.15441038\n",
            "  precision = 0.9740276\n",
            "  recall = 0.9433686\n",
            "  true_negatives = 170643.0\n",
            "  true_positives = 165048.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqQtotLHiuqo",
        "colab_type": "code",
        "outputId": "ceefc947-482b-4b9b-a9fb-c15b16481fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/master/data/labeled_data.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-22 08:30:41--  https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/master/data/labeled_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2546446 (2.4M) [text/plain]\n",
            "Saving to: ‘labeled_data.csv’\n",
            "\n",
            "\rlabeled_data.csv      0%[                    ]       0  --.-KB/s               \rlabeled_data.csv    100%[===================>]   2.43M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-05-22 08:30:41 (25.6 MB/s) - ‘labeled_data.csv’ saved [2546446/2546446]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gxuj6Hwiz85",
        "colab_type": "code",
        "outputId": "2fe12856-c9cd-44f5-b905-4fd60a2196ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "test=pd.read_csv(\"labeled_data.csv\")\n",
        "test=test[test[\"class\"]<=1]\n",
        "test "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24776</th>\n",
              "      <td>25289</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>you're all niggers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24777</th>\n",
              "      <td>25290</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>you're such a retard i hope you get type 2 dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>25291</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>25294</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>25295</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20620 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                              tweet\n",
              "1               1  ...  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2               2  ...  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3               3  ...  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4               4  ...  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
              "5               5  ...  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...\n",
              "...           ...  ...                                                ...\n",
              "24776       25289  ...                                 you're all niggers\n",
              "24777       25290  ...  you're such a retard i hope you get type 2 dia...\n",
              "24778       25291  ...  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
              "24780       25294  ...  young buck wanna eat!!.. dat nigguh like I ain...\n",
              "24781       25295  ...              youu got wild bitches tellin you lies\n",
              "\n",
              "[20620 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLQehBr4WHjj",
        "colab_type": "code",
        "outputId": "1c07eaf3-cf07-46f5-f234-a29ee15b86d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "import pandas as pd\n",
        "testt=pd.read_csv(\"olidtesta.tsv\",sep=\"\\t\")\n",
        "test_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in test[\"tweet\"]]\n",
        "eval_examples = test_examples\n",
        "eval_features = run_classifier.convert_examples_to_features(\n",
        "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "predict_input_fn = run_classifier.input_fn_builder(features=eval_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "predictions = estimator.predict(predict_input_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 20620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 20620\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 20620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 20620\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 20620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 20620\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Started evaluation at 2020-05-22 08:47:02.500587 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YphpFNBv55Wu",
        "colab_type": "code",
        "outputId": "6e66aed1-6c6f-4fb2-cfa3-674f4c93a1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "def get_top_n_words(corpus, n=None):\n",
        "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "common_words = get_top_n_words(test['tweet'], 20)\n",
        "words=[]\n",
        "freqs=[]\n",
        "for word, freq in common_words:\n",
        "    if word not in [\"128514\",\"8220\",\"8221\"]:\n",
        "      words.append(word)\n",
        "      freqs.append(freq)\n",
        "plt.figure(figsize=(20,10)) \n",
        "plt.yticks(size=20)\n",
        "plt.barh(words,freqs,color=\"orange\",)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 17 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQbBm5sy9wRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans5=[]\n",
        "for it in predictions:\n",
        "  ans5.append(it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf4kJsOW_ioW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "pred=[]\n",
        "probs=[]\n",
        "for s,v in zip(testt[\"tweet\"],ans5):\n",
        "  pro=v[\"probabilities\"]\n",
        "  k=np.argmax(pro)\n",
        "  pred.append(k)\n",
        "  probs.append(pro[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2NokEmiAdYZ",
        "colab_type": "code",
        "outputId": "28e7ff52-a07d-4c8f-c9f6-68e4aa7d2844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "truel=list(testt.label)\n",
        "accuracy_score(pred,truel)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-2d3816b4087f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtruel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 860]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOALiUvNBJPV",
        "colab_type": "code",
        "outputId": "ae8e2fe4-fa10-42f9-fb36-9cdba3de3307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(truel,pred)\n",
        "cm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[173,  67],\n",
              "       [ 72, 548]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Ef4vTtVb1P",
        "colab_type": "code",
        "outputId": "d2a7e0a9-a266-4e7a-ee0c-2a2f1c38b936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import auc\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# predict probabilities\n",
        "lr_probs = probs\n",
        "# keep probabilities for the positive outcome only\n",
        "# predict class values\n",
        "lr_precision, lr_recall, _ = precision_recall_curve(truel, lr_probs)\n",
        "lr_f1, lr_auc = f1_score(truel, pred), auc(lr_recall, lr_precision)\n",
        "# summarize scores\n",
        "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
        "# plot the precision-recall curves\n",
        "c=0\n",
        "for i in truel:\n",
        "  if i==0:\n",
        "    c+=1\n",
        "no_skill = c / len(truel)\n",
        "pyplot.plot([1, 0], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_recall, lr_precision, marker='.', label='BERT LARGE')\n",
        "# axis labels\n",
        "pyplot.xlabel('Recall')\n",
        "pyplot.ylabel('Precision')\n",
        "# show the legend\n",
        "pyplot.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic: f1=0.958 auc=0.993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f60bc964c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGCmJPitMCFZ",
        "colab_type": "code",
        "outputId": "a518d272-534f-4dca-b883-7ab24253ed5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(truel,pred,target_names=[\"TIN\",\"UNT\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         TIN       0.95      0.97      0.96    175044\n",
            "         UNT       0.97      0.94      0.96    174956\n",
            "\n",
            "    accuracy                           0.96    350000\n",
            "   macro avg       0.96      0.96      0.96    350000\n",
            "weighted avg       0.96      0.96      0.96    350000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYsji0nKNI-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(truel,pred,target_names=[\"IND\",\"GRP\",\"OTH\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpKkL33dUoKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(truel,pred,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptcnrwo5YhAf",
        "colab_type": "code",
        "outputId": "6c8c1d0e-fd64-46ac-9dd1-c1db8a02238f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>average</th>\n",
              "      <th>std</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4632479</th>\n",
              "      <td>1156316762285080576</td>\n",
              "      <td>@USER Hawkeye had a bow</td>\n",
              "      <td>0.165136</td>\n",
              "      <td>0.189946</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7845126</th>\n",
              "      <td>1188689598399930368</td>\n",
              "      <td>“I’ll stay talking shit till the day someone b...</td>\n",
              "      <td>0.854573</td>\n",
              "      <td>0.162885</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407985</th>\n",
              "      <td>1160606782693101569</td>\n",
              "      <td>And what is wrong with referring to GCF in Tok...</td>\n",
              "      <td>0.298868</td>\n",
              "      <td>0.222644</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4851889</th>\n",
              "      <td>1158592628809707525</td>\n",
              "      <td>@USER Was literally about to send this to you 😂</td>\n",
              "      <td>0.307679</td>\n",
              "      <td>0.246101</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1641634</th>\n",
              "      <td>1162033401853087746</td>\n",
              "      <td>next year i’m going to thailand or some shit a...</td>\n",
              "      <td>0.839686</td>\n",
              "      <td>0.150487</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499809</th>\n",
              "      <td>1161442304810475524</td>\n",
              "      <td>@USER @USER @USER @USER Ah, I fell for the bai...</td>\n",
              "      <td>0.224512</td>\n",
              "      <td>0.131600</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139200</th>\n",
              "      <td>1160789876595396608</td>\n",
              "      <td>@USER @USER @USER Ps, the club didn’t act on i...</td>\n",
              "      <td>0.218473</td>\n",
              "      <td>0.182455</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8713047</th>\n",
              "      <td>1186118617580093442</td>\n",
              "      <td>@USER I see you don’t want me to be a fan anym...</td>\n",
              "      <td>0.607242</td>\n",
              "      <td>0.106090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611501</th>\n",
              "      <td>1158368324318900224</td>\n",
              "      <td>@USER this seems a little angry?  did you appl...</td>\n",
              "      <td>0.357814</td>\n",
              "      <td>0.177934</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1664683</th>\n",
              "      <td>1162071635479760896</td>\n",
              "      <td>@USER Not that annoying homophobic cow girl 😭😭</td>\n",
              "      <td>0.624777</td>\n",
              "      <td>0.297447</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>350000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          id  ... label\n",
              "4632479  1156316762285080576  ...     1\n",
              "7845126  1188689598399930368  ...     0\n",
              "407985   1160606782693101569  ...     1\n",
              "4851889  1158592628809707525  ...     1\n",
              "1641634  1162033401853087746  ...     0\n",
              "...                      ...  ...   ...\n",
              "499809   1161442304810475524  ...     1\n",
              "139200   1160789876595396608  ...     1\n",
              "8713047  1186118617580093442  ...     0\n",
              "4611501  1158368324318900224  ...     1\n",
              "1664683  1162071635479760896  ...     0\n",
              "\n",
              "[350000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epDR5-PKhbG7",
        "colab_type": "code",
        "outputId": "193c6cfd-a9bb-412d-834d-b7e965740dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>average</th>\n",
              "      <th>std</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4014953</th>\n",
              "      <td>1157538642430058496</td>\n",
              "      <td>To steal someone’s wig and wear it freely afte...</td>\n",
              "      <td>0.446529</td>\n",
              "      <td>0.205266</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3754035</th>\n",
              "      <td>1162485298590375936</td>\n",
              "      <td>@USER Alright! Do you want me to DM you on Dis...</td>\n",
              "      <td>0.217854</td>\n",
              "      <td>0.172288</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7214571</th>\n",
              "      <td>1187864398720917504</td>\n",
              "      <td>Ranking  #StarWars Empire New Hope Revenge of ...</td>\n",
              "      <td>0.275036</td>\n",
              "      <td>0.177671</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8987834</th>\n",
              "      <td>1187481168909918209</td>\n",
              "      <td>If I'm annoying say it to my fucken face</td>\n",
              "      <td>0.673865</td>\n",
              "      <td>0.274566</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7192834</th>\n",
              "      <td>1186995062519021568</td>\n",
              "      <td>Begged this mf to make collard greens for me, ...</td>\n",
              "      <td>0.625509</td>\n",
              "      <td>0.209046</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6574065</th>\n",
              "      <td>1188132322035617792</td>\n",
              "      <td>@USER @USER Do we have any chance to see hit i...</td>\n",
              "      <td>0.182339</td>\n",
              "      <td>0.181068</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5693833</th>\n",
              "      <td>1155933443055747073</td>\n",
              "      <td>these folks and they bad ass energy 😒</td>\n",
              "      <td>0.865989</td>\n",
              "      <td>0.155679</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3106915</th>\n",
              "      <td>1162116992851206144</td>\n",
              "      <td>@USER fuck you ate it whole?</td>\n",
              "      <td>0.881532</td>\n",
              "      <td>0.136029</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6953429</th>\n",
              "      <td>1186081823626911744</td>\n",
              "      <td>@USER Come over here too Playa Vista and try d...</td>\n",
              "      <td>0.219700</td>\n",
              "      <td>0.193037</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931217</th>\n",
              "      <td>1160127537931886593</td>\n",
              "      <td>@USER @USER @USER Keyword, economically.  Comp...</td>\n",
              "      <td>0.177693</td>\n",
              "      <td>0.163215</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>350000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          id  ... label\n",
              "4014953  1157538642430058496  ...     1\n",
              "3754035  1162485298590375936  ...     1\n",
              "7214571  1187864398720917504  ...     1\n",
              "8987834  1187481168909918209  ...     0\n",
              "7192834  1186995062519021568  ...     0\n",
              "...                      ...  ...   ...\n",
              "6574065  1188132322035617792  ...     1\n",
              "5693833  1155933443055747073  ...     0\n",
              "3106915  1162116992851206144  ...     0\n",
              "6953429  1186081823626911744  ...     1\n",
              "931217   1160127537931886593  ...     1\n",
              "\n",
              "[350000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z5OR57OAsu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reduce_mean(ten[:,1:3],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js5su9fPq9Qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,2):\n",
        "  t1=tf.reduce_mean(ten[i][1:3],0,keep_dims=True)\n",
        "  t2=tf.reshape(ten[i][0],(1,3))\n",
        "  t1=tf.concat([t2,t1],1)\n",
        "  out.append(t1)\n",
        "tf.convert_to_tensor(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCJcwLkdr-sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.concat([t1,t2],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrkfP0BI1cH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1=tf.reduce_mean(ten[:,1:3],1)\n",
        "t2=ten[:,0]\n",
        "t3=tf.concat([t1,t2],1)\n",
        "print(t3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVQWoBy0BDb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}